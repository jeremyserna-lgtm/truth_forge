# Recording 1769480355

**Date:** 2026-01-27T02:19:15
**Mode:** File Transcription

---

## Analysis

The transcript reveals profound insights about Jeremy Cerna's journey in developing the Truth Engine, a system that captures every aspect of his life and business operations. Here are key insights and meta-level observations:

1. **Radical Transparency and Integrity**: Jeremy's approach to data integrity is radical and unfiltered. He captures every detail of his life, including personal and professional aspects, without censorship. This transparency is not just about data collection but also about the integrity of his system. It challenges the conventional approach of filtering or hiding data that might be deemed inappropriate or embarrassing.

2. **Mental Architecture and Transformation**: The Truth Engine is more than just a data storage system; it's a mental architecture that transforms how Jeremy interacts with his data. It processes information asynchronously, allowing him to focus on other tasks while the system handles routine and complex operations. This transformation is significant as it represents a shift from manual, labor-intensive processes to automated, intelligent workflows.

3. **Business and Personal Integration**: The system integrates business operations with personal life, creating a seamless workflow that operates continuously. This integration is crucial for business efficiency and personal productivity. However, it also raises questions about the boundaries between work and personal life, and the potential for burnout if not managed carefully.

4. **Elastic Honesty and Self-Reflection**: By logging all aspects of his life, including personal struggles and contradictions, Jeremy is practicing what he calls "elastic honesty." This approach forces him to confront his own inconsistencies and biases, leading to a more honest and reflective self. It's a powerful tool for personal growth and self-awareness.

5. **Cybernetic Loop and Externalized Conscience**: The Truth Engine operates as an externalized conscience, enforcing high-integrity principles even when Jeremy might be tempted to deviate. This creates a cybernetic loop where Jeremy's actions are governed by the system's logic, leading to a more consistent and principled behavior. However, it also raises questions about autonomy and the potential for the system to become overly rigid or controlling.

6. **Digital Twin and Identity Continuity**: The Truth Engine acts as a digital twin of Jeremy's mind, capturing his patterns, history, and integrity. This continuity ensures that his identity is preserved and can be accessed and analyzed over time. It's a powerful concept for identity management and personal development, but it also raises ethical questions about privacy and the ownership of personal data.

7. **Future of Human-Machine Interaction**: The Truth Engine represents a future where humans might plug into better versions of themselves, leveraging AI to enhance cognitive and emotional processing. This raises questions about the nature of consciousness, the role of machines in shaping human identity, and the ethical implications of outsourcing parts of our mental processes to digital systems.

These insights highlight the transformative potential of AI in personal and professional development, but also underscore the complex ethical and psychological challenges that come with such radical transparency and integration.

---

## Transcript

Welcome back to the Deep Dive. You know, usually when we sit down to talk about personal data, the conversation goes in one very specific direction. Oh, yeah. It's always about privacy. It's all about privacy. How do I lock my data down? How do I encrypt it? How do I keep the big tech giants from, you know, knowing what I ate for breakfast? Right. It's always a conversation about defense, about building walls. Exactly. But today we are flipping that entire concept completely on its head. We really are. We're looking at a case study that embraced This is something I can only describe as, I don't know, radical, almost aggressive transparency. It is a fascinating pivot. We're looking at a project called the Truth Engine. And just to set the stage here, we aren't talking about a new Fitbit or some journaling app. Not even close. We have a huge stack of sources today. Technical docs, business plans, raw chat logs, personal journals, all revolving around one man, Jeremy Cerna. Digitized existence is not an exaggeration here at all. The scope, I mean, it's all laid out in the complete dataset inventory source, and it is staggering. It is. We aren't looking at a few spreadsheets. No, we're looking at 78 distinct interconnected datasets. And the numbers, they just get crazier. I saw a reference to over 250,000 recorded pattern occurrences. The human mind, concepts, relationships, memories, all mapped out in code. That is what we're dealing with. He calls the apps primitive and terminal. Which sort of implies he sees this as a fundamental operating system for his own life. The phrase that kept jumping out at me in the reading was metabolizing life. The idea that the system doesn't just store data, it like eats it. Whether it's a high-level business strategy or a messy text message sent at 3 in the morning, this truth engine is designed to ingest it, process it, and turn it into structure. Some for capturing entropy. But what really drew me into the architecture was this whole concept of the not me. Yes. The not me. When I first read that in the The Not Me's product document, I thought it sounded like some kind of existential philosophy. It does sound like that. But it's actually a product. It is. And it's a product born out of a very human frustration. Jeremy identifies a problem. He is the bottleneck in his own life and business. He has biological limitations. Which, I mean, we all have. Exactly. He needs to sleep seven or eight hours a day. He can only exist in one time zone at a time. He has finite attention. So he built the not me. And what is it? It is an AI architecture designed specifically to function while the biological Jeremy, the me, is offline. That is the dream, isn't it? To have a version of yourself that just keeps working while you're asleep. But let's get specific. What is the not me actually doing while Jeremy is, you know, catching Z's? Asynchronous cognitive labor. So while he sleeps, the system is researching topics he flagged during the day. It's processing forwarded emails, is drafting briefs for the next morning. It's even answering questions from employees who might be in different time zones. I have to highlight one specific feature here because I think anyone who works in a corporate office is going to be so jealous. Oh, the Just Send It protocol. Yes. This is a brilliant bit of friction reduction. - Right, and think about how much time we spend writing emails that just explain other emails. - See below for context. - Or writing a whole paragraph to summarize a PDF. Jeremy saw that as wasted energy. The Just Send It protocol relies on the fact that the truth engine already has the context. - Because of that knowledge graph we mentioned earlier. - Precisely. The system, specifically the schema registry in the primitive app, is a very simple way to use the system. - The system, specifically the schema registry in the primitive app, is a very simple way to use the system. It acts as a central nervous system. It knows the projects. It knows the history. So if you send it a raw file, it can figure out where it belongs and what to do with it. It connects the dots so the humans don't have to. Exactly. So it's an intelligence layer that sits on top of all the chaos. But underneath that, there is some really heavy technical machinery. The sources talk about a concept called MOLT. Or update your database, you write what's called the migration script. And it's usually a linear, boring, manual process. And always a headache. Always. But in the MOLT service document, Jeremy describes this process not as a script, but as a DNA capability. That sounds biological. That is absolutely the intention. The idea is that the system, the organism, transforms itself. It allows for batch transformation of code, of documents, of services. But here's where it gets really interesting and honestly a little meta. The system uses an inceptive observation pattern. Okay, let's unpack that. Inceptive observation. What does that mean in plain English? Imagine you were writing in a diary. But as you were writing the entry about your day, you were also writing a second entry that describes the act of you writing in the diary. So it's watching itself work. It's recording its own genesis. As the system migrates data or updates its own code, it creates a structured event log of its own actions. Wow. It kind of resolves the black box problem of AI, you know, where you get an output but don't know how it got there. This system keeps a receipt of its own evolution. That is wild. It's self-documenting history. And speaking of history, the system isn't just cold logic. I was looking at the enrichment analysis source, and it seems like he's trying to teach the machine to understand feeling. So it's reading his texts and emails. Right, the economic sophomy. I loved this document because you have all this high concept philosophy about metabolizing life and DNA capabilities, but then you have a document that asks this brutal question, how much do I make at the speed I already exist? And the numbers are laid out right there in the spreadsheet. Projected revenue targets from a minimum of 130k to 500k capacity. But my favorite detail in this whole section. Let me guess. The mistake budget. The mistake budget. It made it feel so real. There was a specific incident mentioned, a $900 Google Cloud bill from a runaway BigQuery query. Oh, we have all been there. You leave a process running, you wake up and you owe some tech giant a lot of money. $900 is a painful It is. And there was another $400 charge for API overuse. But the insight in the document isn't just oops. The insight is that when you are building a digital brain, mistakes cost real money. AI hallucinations or infinite loops aren't just glitches, they are expenses. So he explicitly budgets for the AI screwing up. It's a line item. It's the cost of doing business with a digital brain. Now, we should mention that this isn't just a personal science project. There's a commercial B2B product attached to this. What is that? Yes, Credential Atlas is the commercial face of the operation. It is an intelligence platform for education data. So it aggregates things like IPED as completion data and Bureau of Labor Statistics wages. The scale looks impressive in the status file. It says they are tracking 10.8 million completions. Ten emails. That is the classic builder's trap, right? You build the perfect system, but you forget to actually go sell it. True. But his argument for the product's value, his moat, is fascinating. He claims Credential Atlas is built on the Truth Engine parent system. So he's using his personal AI to do business analysis. Exactly. He's using this personal AI infrastructure to do, in weeks, what took teams of analysts months to do at his previous job. That connects to the universal membrane offer. And what a sales pitch. Thinking as infrastructure. It is a bold proposition. The offer isn't software, it's a socket. He's pitching companies to plug into his recursive intelligence. He calls it a universal membrane. So you aren't buying an app, you're buying access to a verified, high-integrity way of processing information. That's the idea. So, okay, that covers the business and the tech. But we need to pivot. Because if you stop reading there, this just sounds like a very advanced, very cool productivity tool. Right. This gets complicated and very personal. This is where we enter the concept of the furnace. The furnace. What is that? Jeremy describes his internal process as truth leads to meaning, which leads to care. The goal of the furnace is to take raw entropy, all the chaos, the trauma, the life events, and forge it into value. And the phrase total metabolism appears here again. That is the key differentiator. Most people repress things. We have waste products in our psychology. Memories we ignore, shame we bury, weekends we'd rather forget. Sure. The truth engine has zero repression. It processes everything. Everything. Addiction, crisis, hallucinations, it all gets logged as data. There's a haunting phrase in the documentation, the Museum of Shed Skins. It's a beautiful, if slightly eerie, concept. Because the system tracks changes over time, the 51.8 million entities in the database act as a mausoleum. He can query Jeremy of July 2025 and see, So he's not just remembering his past, he can literally interact with it. Correct. But for that interaction to be valuable, the data has to be accurate. It has to be the whole truth. And this brings us to the most paradoxical part of the source material. We have to look at the analysis of paradoxical life and the Zoom chat transcript. This is where the rubber really meets the road on total metabolism. The documents describe this massive contradiction in Jeremy's life. They do. On one hand, Jeremy identifies as a committed Christian. He talks about the same thing. He's a real person. He's a real person. He's a real person. He's a real person. He's a real person. He's a real person. He's a real person. He's a real person. He's a real person. He's a real person. He's a real person. He's a real person. He's a real person. He's a real person. He's a real person. He's a real person. He's a real person. He's a real person. He's a real person. He's a real person. He's a real person. He's a real person. He's a real person. He's a real person. He's a real person. He's a real person. He's a real person. But then you look at the logs from a Zoom room called the VI room, and the content is, well, it's radically different. It reports on what the text calls radical openness. The transcripts document a mix of high-level technical architecture discussions happening right alongside recreational drug use. And they're specific. Methamphetamine. Yes. And casual sexual encounters. And he continues, mentioning smoking with two cute guys at a trailer his stepfather used to own. He even notes the history of that location, saying his stepfather burned his lungs tearing down a trailer that was used for meth. Truth engine builder discussing the architecture of his soul in one document, and this is a very raw, gritty reality in the next. So the point of the truth engine, and this is absolutely crucial, is that these things aren't hidden. Right. Usually if you are building a legacy system for yourself, you scrub the bad parts, you delete the logs. You curate the saint and hide the sinner. Yeah. Exactly. But Jeremy's argument is that if the goal is a truth engine, you cannot filter the data. This connects back to that concept of elastic honesty. The system captures the saint and sinner archetype without filtering. So if he deleted the drug use or the sexual encounters, the system would be broken. It would be training on a lie. The system validates itself by capturing all of him. The professional facade and the personal chaos are treated with the exact same data integrity. It validates that the machine is working because it refuses to look away. Precisely. That is intense. It takes a lot of guts to code your own contradictions into a database. But it raises a really big question. Who is in charge here? The man or the machine? That is the focus of the next section: the system as governor. The Undocumented Insights document reveals something profound. Which is? The system has become more rigid than its creator. In what way? It acts as an externalized conscience. The document describes it as a superego, or a governor. Because the system was built on logic and high integrity principles, it enforces those principles, even when the human Jeremy is tired, or tempted to slide back into, you know, lower So he built a better version of himself and now that version bosses him around. In a sense. It creates what they call a cybernetic loop. The documents outline the cycle. Jeremy built the system. The system defined him through data. And now the system sustains him. He is no longer just a user of this software. He's a component. The text actually describes him as the biological component of a larger cognitive organism. The system holds his history, his integrity, and his patterns better than the other. It's almost like he's outsourced his soul to the cloud, or maybe secured it there so he can't mess it up. It's a bit of both. It ensures a continuity of character even when the human falls short. So let's zoom out and just look at the full picture. We have a man who built a massive data infrastructure to capture his entire life, 78 datasets, quarter of a million patterns. It's called the Truth Engine. It includes business plans, automated workflows that run while he sleeps to make money, and a not-me product that serves clients. And it includes a total metabolism of his personal life, from spiritual aspirations to drug use and sexual encounters, all logged, analyzed, and preserved without judgment. It is a mausoleum of identity where nothing is wasted. Crisis becomes architecture. And the "not me" ensures value is created even when the human is offline. Jeremy has built a digital twin of his mind. And unlike a jet engine, this twin captures the internal conflict. It forces us to ask, if this machine remembers Jeremy better than Jeremy remembers Jeremy, which one is the real authority? That is the lingering question. It is. We'll leave you with a final thought from the Universal Membrani offer. Jeremy asks us to imagine thinking as infrastructure. If a system can hold your history, your integrity, and your patterns better than you can, are we approaching a future where we don't just use computers, but we simply plug in to better versions of ourselves. And if we do, do we get to choose which parts of us the machine keeps? Or does it keep everything? Something to chew on. Thanks for diving deep with us. We'll see you next time.
